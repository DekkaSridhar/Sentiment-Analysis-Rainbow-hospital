{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cbfbad6-25b9-47da-9626-98e08b4e65cc",
   "metadata": {},
   "source": [
    "# Main Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b08223a-0378-4b80-9fcb-6a3327854e80",
   "metadata": {},
   "source": [
    "## bert-base-uncased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0d7c12-f499-4581-80fd-2a1d5b49e1f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e92e83e3-e666-4f0c-a192-392bc5ad9584",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\990754\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag, ne_chunk\n",
    "from collections import defaultdict\n",
    "from transformers import pipeline, BertTokenizer, BertForSequenceClassification\n",
    "from nltk import RegexpParser\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  # Ignore all warnings\n",
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77ec4e41-1b73-4489-a860-982cd22c1efd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hospital</th>\n",
       "      <th>username</th>\n",
       "      <th>reviews</th>\n",
       "      <th>stars_given</th>\n",
       "      <th>Branch location</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Popular times</td>\n",
       "      <td>srividya ande</td>\n",
       "      <td>I am very much satisfied by outstanding dental...</td>\n",
       "      <td>5</td>\n",
       "      <td>Telangana 500072</td>\n",
       "      <td>a week ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Popular times</td>\n",
       "      <td>indrani das</td>\n",
       "      <td>My mom is very much satisfied by the dental tr...</td>\n",
       "      <td>5</td>\n",
       "      <td>Telangana 500072</td>\n",
       "      <td>a week ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Popular times</td>\n",
       "      <td>Eswaramma Eswari</td>\n",
       "      <td>My daughter is six months into her Invisalign ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Telangana 500072</td>\n",
       "      <td>2 weeks ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Popular times</td>\n",
       "      <td>Mahesh Sainathuni</td>\n",
       "      <td>If someone is looking for a dental care or tre...</td>\n",
       "      <td>5</td>\n",
       "      <td>Telangana 500072</td>\n",
       "      <td>9 months ago</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Hospital           username  \\\n",
       "0  Popular times      srividya ande   \n",
       "1  Popular times        indrani das   \n",
       "2  Popular times   Eswaramma Eswari   \n",
       "3  Popular times  Mahesh Sainathuni   \n",
       "\n",
       "                                             reviews  stars_given  \\\n",
       "0  I am very much satisfied by outstanding dental...            5   \n",
       "1  My mom is very much satisfied by the dental tr...            5   \n",
       "2  My daughter is six months into her Invisalign ...            5   \n",
       "3  If someone is looking for a dental care or tre...            5   \n",
       "\n",
       "    Branch location          Time  \n",
       "0  Telangana 500072    a week ago  \n",
       "1  Telangana 500072    a week ago  \n",
       "2  Telangana 500072   2 weeks ago  \n",
       "3  Telangana 500072  9 months ago  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data into a DataFrame\n",
    "dt = pd.read_csv(r\"C:\\Users\\990754\\Downloads\\sentiment-analysis-python\\data.csv\")\n",
    "dt.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1d8250-dd23-495a-bc67-f054aaec3b80",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2e3fd3f-aebb-4e70-960c-2633572d62e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hospital           0\n",
       "username           0\n",
       "reviews            0\n",
       "stars_given        0\n",
       "Branch location    0\n",
       "Time               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding the columns having null values\n",
    "dt.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1953b8fe-7db5-468a-ad2d-a58cd79b8dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where 'reviews' column is null\n",
    "dt = dt.dropna(subset=['reviews'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3d21b42-5c85-4ed7-a834-f3aef6bd24d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where 'Hospital' column has the value \"Web results\"\n",
    "dt = dt[dt['Hospital'] != 'Web results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33865672-5058-43c2-9699-2d441fe7d6f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hospital</th>\n",
       "      <th>username</th>\n",
       "      <th>reviews</th>\n",
       "      <th>stars_given</th>\n",
       "      <th>Branch location</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19193</th>\n",
       "      <td>Pediatric Outpatient Department - Rainbow Chil...</td>\n",
       "      <td>Santosh Thirumani</td>\n",
       "      <td>good service</td>\n",
       "      <td>5</td>\n",
       "      <td>Telangana 500074</td>\n",
       "      <td>10 months ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19194</th>\n",
       "      <td>Pediatric Outpatient Department - Rainbow Chil...</td>\n",
       "      <td>venkatkistareddy gaveni</td>\n",
       "      <td>Good</td>\n",
       "      <td>5</td>\n",
       "      <td>Telangana 500074</td>\n",
       "      <td>10 months ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19195</th>\n",
       "      <td>Pediatric Outpatient Department - Rainbow Chil...</td>\n",
       "      <td>Mahesh kumar</td>\n",
       "      <td>Good</td>\n",
       "      <td>5</td>\n",
       "      <td>Telangana 500074</td>\n",
       "      <td>10 months ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19196</th>\n",
       "      <td>Pediatric Outpatient Department - Rainbow Chil...</td>\n",
       "      <td>Charan cherry</td>\n",
       "      <td>K goodIndhu</td>\n",
       "      <td>4</td>\n",
       "      <td>Telangana 500074</td>\n",
       "      <td>10 months ago</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Hospital  \\\n",
       "19193  Pediatric Outpatient Department - Rainbow Chil...   \n",
       "19194  Pediatric Outpatient Department - Rainbow Chil...   \n",
       "19195  Pediatric Outpatient Department - Rainbow Chil...   \n",
       "19196  Pediatric Outpatient Department - Rainbow Chil...   \n",
       "\n",
       "                      username       reviews  stars_given   Branch location  \\\n",
       "19193        Santosh Thirumani  good service            5  Telangana 500074   \n",
       "19194  venkatkistareddy gaveni          Good            5  Telangana 500074   \n",
       "19195             Mahesh kumar          Good            5  Telangana 500074   \n",
       "19196            Charan cherry   K goodIndhu            4  Telangana 500074   \n",
       "\n",
       "                Time  \n",
       "19193  10 months ago  \n",
       "19194  10 months ago  \n",
       "19195  10 months ago  \n",
       "19196  10 months ago  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.tail(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c25c6e-b9cd-4d4f-8816-775a0a7c9ffd",
   "metadata": {},
   "source": [
    "## Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2be382ec-45ca-4f64-80b0-260004928f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained sentiment analysis model\n",
    "sentiment_analysis = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "# Define the model name\n",
    "MODEL_NAME = \"bert-base-uncased\"\n",
    "\n",
    "# Load pre-trained tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Load pre-trained model for sequence classification\n",
    "model = BertForSequenceClassification.from_pretrained(MODEL_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33158b04-3baf-48bf-a8ef-a64702be1bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to extract sentiment of a review\n",
    "def get_review_sentiment(review):\n",
    "    # Truncate the review to the maximum input length supported by the model (512 tokens)\n",
    "    truncated_review = review[:512]\n",
    "    # Perform sentiment analysis\n",
    "    result = sentiment_analysis(truncated_review)\n",
    "    return result[0]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f2616f0-d34b-474c-9e14-9685a2a341ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_aspects(sentence, sentiment):\n",
    "    tokenized_sentence = word_tokenize(sentence)\n",
    "    tagged_words = pos_tag(tokenized_sentence)\n",
    "    \n",
    "    # Define a regular expression pattern for detecting noun phrases with associated modifiers\n",
    "    grammar = r\"\"\"\n",
    "        NP: {<DT|JJ.*|NN.*>+}      # Chunk sequences of determiner, adjective, and noun\n",
    "        VB: {<VB.*>}                # Chunk sequences of verbs\n",
    "        RB: {<RB.*>}                # Chunk sequences of adverbs\n",
    "    \"\"\"\n",
    "    parser = RegexpParser(grammar)\n",
    "    parsed_sentence = parser.parse(tagged_words)\n",
    "    \n",
    "    nouns = defaultdict(list)\n",
    "    adjectives = defaultdict(list)\n",
    "    verbs = defaultdict(list)\n",
    "    adverbs = defaultdict(list)\n",
    "    \n",
    "    for subtree in parsed_sentence.subtrees():\n",
    "        if subtree.label() == 'NP':\n",
    "            noun = \"\"\n",
    "            adjectives_list = []\n",
    "            for word, pos in subtree.leaves():\n",
    "                if pos.startswith(\"NN\"):  # Nouns\n",
    "                    noun += word + \" \"\n",
    "                elif pos.startswith(\"JJ\"):  # Adjectives\n",
    "                    adjectives_list.append(word)\n",
    "            noun = noun.strip()\n",
    "            if adjectives_list:\n",
    "                adjectives[noun] = adjectives_list\n",
    "            else:\n",
    "                nouns[noun] = []\n",
    "        elif subtree.label() == 'VB':  # Verbs\n",
    "            verb = \" \".join(word for word, pos in subtree.leaves())\n",
    "            verbs[verb] = []\n",
    "        elif subtree.label() == 'RB':  # Adverbs\n",
    "            adverb = \" \".join(word for word, pos in subtree.leaves())\n",
    "            adverbs[adverb] = []\n",
    "    \n",
    "    return nouns, adjectives, verbs, adverbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a540670-8a03-4bcf-822a-d7162fe2ea0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to process each review\n",
    "def process_review(review):\n",
    "    if not review or not review.strip():  # Check if review is None or contains only whitespace\n",
    "        return \"UNKNOWN\", defaultdict(list), defaultdict(list)\n",
    "    \n",
    "    sentiment = get_review_sentiment(review)\n",
    "    parts = re.split(r'[,.]', review)\n",
    "    sustain_part = defaultdict(list)\n",
    "    improve_part = defaultdict(list)\n",
    "    \n",
    "    for part in parts:\n",
    "        if not part or not part.strip():  # Skip empty parts or parts containing only whitespace\n",
    "            continue\n",
    "        \n",
    "        part_sentiment = get_review_sentiment(part)\n",
    "        nouns, adjectives, verbs, adverbs = extract_aspects(part, part_sentiment)\n",
    "        \n",
    "        for noun, adj_list in adjectives.items():\n",
    "            if noun.strip() and adj_list:  # Check if both noun and adjectives are non-empty\n",
    "                if sentiment == \"POSITIVE\" and part_sentiment == \"POSITIVE\":\n",
    "                    sustain_part[noun].extend(adj_list)\n",
    "                elif sentiment == \"NEGATIVE\" and part_sentiment == \"NEGATIVE\":\n",
    "                    improve_part[noun].extend(adj_list)\n",
    "        \n",
    "        for noun, verb_list in verbs.items():\n",
    "            if noun.strip() and verb_list:  # Check if both noun and verbs are non-empty\n",
    "                if sentiment == \"POSITIVE\" and part_sentiment == \"POSITIVE\":\n",
    "                    sustain_part[noun].extend(verb_list)\n",
    "                elif sentiment == \"NEGATIVE\" and part_sentiment == \"NEGATIVE\":\n",
    "                    improve_part[noun].extend(verb_list)\n",
    "        \n",
    "        for noun, adv_list in adverbs.items():\n",
    "            if noun.strip() and adv_list:  # Check if both noun and adverbs are non-empty\n",
    "                if sentiment == \"POSITIVE\" and part_sentiment == \"POSITIVE\":\n",
    "                    sustain_part[noun].extend(adv_list)\n",
    "                elif sentiment == \"NEGATIVE\" and part_sentiment == \"NEGATIVE\":\n",
    "                    improve_part[noun].extend(adv_list)\n",
    "    \n",
    "    # Convert defaultdicts to dictionaries\n",
    "    sustain_part = dict(sustain_part)\n",
    "    improve_part = dict(improve_part)\n",
    "    \n",
    "    return sentiment, sustain_part, improve_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eed5632-f84f-4396-ae1a-d7e77f82af6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply processing to each review\n",
    "sentiments, sustains, improvements = zip(*dt['reviews'].apply(process_review))\n",
    "\n",
    "# Add sentiment, sustain, and improvement parts to DataFrame\n",
    "dt['sentiment_analysis'] = sentiments\n",
    "dt['sustain'] = sustains\n",
    "dt['improvement'] = improvements\n",
    "dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d633bd3-b23b-4ead-a770-335f7f4aa7e6",
   "metadata": {},
   "source": [
    "## Creating Word Cloud column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33b526e8-a96e-468a-b3c9-65a299c19fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract nouns from a sentence\n",
    "def extract_nouns(sentence):\n",
    "    tokenized_sentence = word_tokenize(sentence)\n",
    "    tagged_words = pos_tag(tokenized_sentence)\n",
    "    \n",
    "    named_entities = []\n",
    "    for chunk in ne_chunk(tagged_words):\n",
    "        if hasattr(chunk, 'label') and chunk.label():\n",
    "            named_entities.append(' '.join(c[0] for c in chunk))\n",
    "    \n",
    "    nouns = []\n",
    "    for word, pos in tagged_words:\n",
    "        if pos.startswith(\"NN\") and not pos.startswith(\"NNP\") and word not in named_entities:  # Exclude proper nouns and named entities\n",
    "            nouns.append(word)\n",
    "    \n",
    "    return nouns\n",
    "\n",
    "# Function to process each review\n",
    "def process_review(review):\n",
    "    if not review or not review.strip():  # Check if review is None or contains only whitespace\n",
    "        return \"\"\n",
    "    \n",
    "    nouns = extract_nouns(review)\n",
    "    \n",
    "    # Remove plural nouns\n",
    "    nouns = [word for word in nouns if not wn.synsets(word) or not wn.synsets(word)[0].name().split('.')[0].endswith('s')]\n",
    "    \n",
    "    return \" \".join(nouns)\n",
    "\n",
    "# Load your DataFrame with the 'reviews' column\n",
    "# Assuming your DataFrame is named 'dt'\n",
    "# Add a new column 'wordCloud' filled with extracted nouns\n",
    "dt['wordCloud'] = dt['reviews'].apply(process_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e22aff5-c82e-4551-8417-2df22daf6f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a new CSV file if needed\n",
    "dt.to_csv(\"processed_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3b40e1-b438-41c0-9005-e1e1a5ed8429",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599d42dc-af9f-4076-90a1-fe6c606277c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c348ead6-b2fe-4dc8-b5ad-ee03e63595bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
